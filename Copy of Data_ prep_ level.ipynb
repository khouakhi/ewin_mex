{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_ prep_ level.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"37yGtcuc7IOR","colab_type":"text"},"source":["### Import the necessary modules and packages"]},{"cell_type":"code","metadata":{"id":"IbaELqOMbPtP","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","from zipfile import ZipFile   \n","from glob import glob\n","from datetime import datetime\n","from matplotlib.dates import DateFormatter, MonthLocator\n","# read level file example \n","!pip install timestring\n","import timestring"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k0EAuPwn8KbW","colab_type":"text"},"source":["### Map google drive to read and save files "]},{"cell_type":"code","metadata":{"id":"I_-Gx4_7hbIh","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9U8ve80K9j1T","colab_type":"text"},"source":["### Data source directory "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xo_MNVU9d57T","colab":{}},"source":["data_source = '/content/drive/My Drive/ewin_mex_data/'\n","file_names = os.listdir(data_source)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r4SDtXoD9wDF","colab_type":"text"},"source":["### Create an empty folder to unzip files"]},{"cell_type":"code","metadata":{"id":"6HY-rGphqj-G","colab_type":"code","colab":{}},"source":["# Create an empty folder (if it doesnt exist) for the unzipped files\n","unzip_data_folder = os.path.join(data_source,\"unzipped_data\")\n","try:\n","    os.mkdir(unzip_data_folder)\n","except OSError:\n","    print (\"folder exists already %s:\" % unzip_data_folder)\n","else:\n","    print (\"Successfully created the directory %s \" % unzip_data_folder)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FnmQ0IhL9_eC","colab_type":"text"},"source":["### Unzip all documents recursively "]},{"cell_type":"code","metadata":{"id":"WDtA71kHzDsS","colab_type":"code","colab":{}},"source":["# function that goes through folders and unzip fils \n","def unzip_files(data_source,output_file):\n","  for path, dir_list, file_list in os.walk(data_source):\n","      for file_name in file_list:\n","          if file_name.endswith(\".zip\"):\n","              abs_file_path = os.path.join(path, file_name)\n","              print(abs_file_path)\n","              zip_obj = ZipFile(abs_file_path, 'r')\n","              zip_obj.extractall(output_file)\n","              zip_obj.close()\n","  print(\"Successfully unzipped!\")   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVtGpV8G7vQb","colab_type":"code","colab":{}},"source":["# apply the function \n","unzip_files(data_source=data_source, output_file=unzip_data_folder)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_AuwGz7B-2Rx","colab_type":"text"},"source":["### RiverCore data\n","Find all file paths "]},{"cell_type":"code","metadata":{"id":"ApKr_apw894T","colab_type":"code","colab":{}},"source":["# find level files \n","all_lvl_files = []\n","substring = \"Node\"#_10\n","for root, subdirs, files in os.walk(unzip_data_folder):\n","        for filename in files:\n","            if substring in filename:\n","                name_path = os.path.join(root,filename)\n","                all_lvl_files.append(name_path)\n","                \n","print(all_lvl_files)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ugmDKBNjDpRQ","colab_type":"text"},"source":["### Datetime management libraries "]},{"cell_type":"code","metadata":{"id":"Y2dVEINGg37k","colab_type":"code","colab":{}},"source":["# read level file example \n","data = pd.read_csv(all_lvl_files[7],sep='\\t',error_bad_lines=False, engine='python') #, header=None \n","# Data summary\n","print(data.dtypes)\n","print(data.describe())\n","print(data.columns)\n","# rename variables \n","new_columns = ['time_stamp','wl', 'sm']\n","data.columns = new_columns\n","# Check for NaNs\n","data.isna().any()\n","# remove last digits from time_stamp \n","data['time_stamp'] = data['time_stamp'].str[:-5]+data['time_stamp'].str[-1:]\n","# correct the month name\n","if 'September'in all_lvl_files[7]:\n","  data['time_stamp'] = data['time_stamp'].str.replace('Septeber','september')\n","#apply timestring function \n","data['time_stamp'] = data['time_stamp'].apply(timestring.Date) \n","# convert date to string\n","data['time_stamp'] = data['time_stamp'].apply(str)\n","# parse datetime\n","data['time_stamp'] = pd.to_datetime(data['time_stamp'], format='%Y-%m-%d %H:%M:%S') \n","#print(data.describe())\n","# convert stage to numeric\n","data['wl'] = data['wl'].apply(pd.to_numeric, errors='coerce')\n","data['sm'] = data['sm'].apply(pd.to_numeric, errors='coerce')\n","# set time_stamp as index\n","data = data.set_index('time_stamp')\n","# print dtypes \n","print(data.dtypes)\n","# aggregate to hourly ts\n","hourly_lvl = data.resample('h').mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ib9see4x9kmX","colab_type":"code","colab":{}},"source":["plt.plot(hourly_lvl['wl'])\n","plt.plot(hourly_lvl['sm'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7kkeMQqABkl3","colab_type":"text"},"source":["### Define a function that reads the level files and exports tidy files "]},{"cell_type":"code","metadata":{"id":"jxrLscytoPSy","colab_type":"code","colab":{}},"source":["def lvl_data_prep(file_name):\n","  data = pd.read_csv(file_name,sep='\\t',error_bad_lines=False, engine='python') #, header=None \n","  # rename variables \n","  new_columns = ['time_stamp','wl', 'sm']\n","  data.columns = new_columns\n","  # remove the wrong rows\n","  data.isna().any()\n","  # remove last digits from time \n","  data['time_stamp'] = data['time_stamp'].str[:-5]+data['time_stamp'].str[-1:]\n","  # correct September \n","  if 'September'in file_name:\n","    data['time_stamp'] = data['time_stamp'].str.replace('Septeber','september')  \n","  # remove rows with \"e\"\n","  data = data[data.time_stamp!=\"e\"]\n","  # apply the timestring function \n","  data['time_stamp'] = data['time_stamp'].apply(timestring.Date) \n","  # convert date to string\n","  data['time_stamp'] = data['time_stamp'].apply(str)\n","  # parse dates \n","  data['time_stamp'] = pd.to_datetime(data['time_stamp'], format='%Y-%m-%d %H:%M:%S') \n","  # convert stage to numeric\n","  data['wl'] = data['wl'].apply(pd.to_numeric, errors='coerce')\n","  data['sm'] = data['sm'].apply(pd.to_numeric, errors='coerce')\n","  # set time_stamp as index\n","  data = data.set_index('time_stamp')\n","  # aggerate to hourly data\n","  hourly_data = data.resample('h').mean()\n","  return(hourly_data)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"94FLRI6CClVs","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"qLuIGlqkDNWa","colab_type":"code","colab":{}},"source":["# create new folder for the processed precip data\n","hourly_level = os.path.join(data_source,\"hourly_level\")\n","try:\n","    os.mkdir(hourly_level)\n","except OSError:\n","    print (\"file exists already %s:\" % hourly_level)\n","else:\n","    print (\"Successfully created the directory %s \" % hourly_level)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N9lpXIgbeiIm","colab_type":"text"},"source":["### aggregate to hourly and save files by station"]},{"cell_type":"code","metadata":{"id":"vQktBg7-Buq9","colab_type":"code","colab":{}},"source":["# iterate through all rainfall files  \n","for lvl_file in all_lvl_files:\n","  print(lvl_file)\n","  hourly_lvl = lvl_data_prep(lvl_file)\n","  # new file name\n","  rc_stations = ['Node'+str(i) for i in range(1,15)]\n","  for nd in rc_stations:\n","    if nd in lvl_file:\n","      fname = nd\n","  # define path \n","  new_name_path = os.path.join(hourly_level,f'rc_{fname}.csv')\n","  # if the file exists append, if not create new\n","  if os.path.isfile(new_name_path):\n","    hourly_lvl.to_csv(new_name_path,   mode='a', header=False)\n","  else:\n","    hourly_lvl.to_csv(os.path.join(hourly_level,f'rc_{fname}.csv'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_i6diPqhRznG","colab_type":"text"},"source":["### plot levels"]},{"cell_type":"code","metadata":{"id":"XJF0t_x19soA","colab_type":"code","colab":{}},"source":["# list files\n","lvl_file_names = os.listdir(hourly_level)\n","# Initialize the figure\n","plt.style.use('seaborn-whitegrid')\n","# create a color palette\n","palette = plt.get_cmap('Set3')\n","\n","fig = plt.figure(figsize=(20, 12))\n","num = 0\n","for i in lvl_file_names:\n","  this_file = os.path.join(hourly_level,i)\n","  df = pd.read_csv(this_file,infer_datetime_format= True,\n","                   parse_dates=True,index_col='time_stamp') \n","  # sort by datetime\n","  df = df.sort_values(by=['time_stamp'])\n","  df = df.resample('h').mean()\n","  num+=1\n","  ax = fig.add_subplot(3,3, num)\n","  ax.plot(df['wl'], marker='', color='blue', linewidth=1.9, alpha=0.9, label=i)\n"," # Add title\n","  plt.title(i[:-4], loc='center', fontsize=12, fontweight=0, color=\"black\")\n","# general title\n","  plt.suptitle(\"EWIN Mex Water level \", fontsize=25, fontweight=0,\n","               color='black', style='italic', y=1.02)\n","\n","  months = MonthLocator()\n","  monthsFmt = DateFormatter(\"%b-%Y\")\n","  ax.xaxis.set_major_locator(months)\n","  ax.xaxis.set_major_formatter(monthsFmt)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QOTEAboMcYAy","colab_type":"text"},"source":["### Atmos data"]},{"cell_type":"code","metadata":{"id":"9KxmZRHicVD-","colab_type":"code","colab":{}},"source":["unzip_data_folder = os.path.join(data_source,\"unzipped_data\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"l7rR3vXniLPY"},"source":["### Find all ATMOS file paths "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Fn8k5DIDiLQD","colab":{}},"source":["# find level files \n","all_prcp_files = []\n","substring = \"_10\"\n","for root, subdirs, files in os.walk(unzip_data_folder):\n","        for filename in files:\n","            if substring in filename:\n","                name_path = os.path.join(root,filename)\n","                all_prcp_files.append(name_path)\n","                \n","all_prcp_files"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HVmxN0DO74RS","colab_type":"text"},"source":["\n","\n"]},{"cell_type":"code","metadata":{"id":"6OOU2CeC748Q","colab_type":"code","colab":{}},"source":["# create new folder for the processed precip data\n","hourly_atmos = os.path.join(data_source,\"hourly_atmos\")\n","try:\n","    os.mkdir(hourly_atmos)\n","except OSError:\n","    print (\"file exists already %s:\" % hourly_atmos)\n","else:\n","    print (\"Successfully created the directory %s \" % hourly_atmos)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tFgr2aiZlGEt","colab":{}},"source":["for p in all_prcp_files:\n","  print(p)\n","  # date parser \n","  dparser = lambda x:datetime.strptime(x, \"%d/%m/%Y %H:%M\")\n","  # read txt file   \n","  if 'sep' in p:\n","    data = pd.read_csv(p,sep='\\t',\n","                parse_dates=['Date'],\n","                index_col='Date',\n","                date_parser = dparser,\n","                error_bad_lines=False,\n","                encoding='utf-16')\n","  else:\n","    data = pd.read_csv(p,sep='\\t',\n","                parse_dates=['Date'],\n","                index_col='Date',\n","                date_parser = dparser,\n","                error_bad_lines=False)  \n","  # rename variables \n","  new_columns = ['air_temp','relative_hum', 'prcp','solar_rad','vapor_press']\n","  data.columns = new_columns\n","  # set time_stamp as index\n","  data.index.names = ['time_stamp']\n","  # remove the wrong rows\n","  data.isna().any()\n","  data.dtypes\n","  print('missing data per column:\\n',data.isnull().sum())\n","  # find missing data\n","  missing_data = data[data['air_temp'].isnull()]\n","  # quick plot \n","  data['prcp'].plot()\n","\n","  set1_noPrcp = data.drop('prcp',1).resample('h').mean()\n","  set2_Prcp = data.prcp.resample('h').sum(min_count=1)\n","  # to hourly \n","  atmos_hourly = pd.concat([set1_noPrcp, set2_Prcp], axis=1)\n","  # new file name\n","  atmos_stations = ['Atmos'+str(i) for i in range(1,9)]\n","  for s in atmos_stations:\n","    if s in p:\n","      fname = s\n","  # define path \n","  new_name_path = os.path.join(hourly_atmos,f'{fname}.csv')\n","  # if the file exists append, if not create new\n","  if os.path.isfile(new_name_path):\n","    atmos_hourly.to_csv(new_name_path,mode='a', header=False)\n","  else:\n","    atmos_hourly.to_csv(os.path.join(hourly_atmos,f'{fname}.csv'))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pui9yG2CZshu","colab_type":"code","colab":{}},"source":["# list files\n","prcp_file_names = os.listdir(hourly_atmos)\n","# Initialize the figure\n","plt.style.use('seaborn-whitegrid')\n","# variable to plot across stations\n","var = \"prcp\"\n","# fugure config \n","fig = plt.figure(figsize=(20, 12))\n","num = 0\n","for i in prcp_file_names:\n","  this_file = os.path.join(hourly_atmos,i)\n","  df = pd.read_csv(this_file,infer_datetime_format= True,\n","                   parse_dates=True,index_col='time_stamp') \n","  # sort by datetime\n","  df = df.sort_values(by=['time_stamp'])\n","  df = df.resample('h').mean()\n","  num+=1\n","  ax = fig.add_subplot(3,3, num)\n","  ax.plot(df[var], marker='', color='blue', linewidth=1.9, alpha=0.9, label=i)\n"," # Add title\n","  plt.title(i[:-4]+var, loc='center', fontsize=12, fontweight=0, color=\"black\")\n","# general title\n","  plt.suptitle(\"EWIN Mex Atmos \", fontsize=25, fontweight=0,\n","               color='black', style='italic', y=1.02)\n","\n","  months = MonthLocator()\n","  monthsFmt = DateFormatter(\"%b-%Y\")\n","  ax.xaxis.set_major_locator(months)\n","  ax.xaxis.set_major_formatter(monthsFmt)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OGAxYXdUsgXk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c509fd66-9911-452c-97c1-cf52df8e3afa","executionInfo":{"status":"ok","timestamp":1577805415100,"user_tz":0,"elapsed":977,"user":{"displayName":"Abdou KHOUAKHI","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCmeyp0CAemaGTjuHY2DFExPnmBmtIDxTLdxc8O6Q=s64","userId":"08254891030733884876"}}},"source":[""],"execution_count":166,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":166}]}]}