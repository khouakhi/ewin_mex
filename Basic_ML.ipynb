{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basic_ML.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RpbBit7ClxnC","colab_type":"text"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/khouakhi/ewin_mex/blob/master/%20Data_%20prep_%20level.ipynb)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uBBqFdFgpoO2","colab_type":"text"},"source":["> You need to run [Data prep1](https://colab.research.google.com/github/khouakhi/ewin_mex/blob/master/RC_data_prep1.ipynb) and [Data prep2](https://colab.research.google.com/github/khouakhi/ewin_mex/blob/master/RC_data_prep2.ipynb) notebooks before running this one.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MBuAJMT3BJWC","colab_type":"text"},"source":["Run the first two cells if you open this notebook in Colab"]},{"cell_type":"code","metadata":{"id":"I_-Gx4_7hbIh","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YH-EeNPnlg9x","colab_type":"code","colab":{}},"source":["%cd './drive/My Drive'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkN4K0G2rzGx","colab_type":"code","colab":{}},"source":["import pandas as pd \n","import matplotlib.pyplot as plt \n","import os\n","from math import sqrt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9U8ve80K9j1T","colab_type":"text"},"source":["#### Data source path "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xo_MNVU9d57T","colab":{}},"source":["data_source = './ewin_mex/data'\n","file_names = os.listdir(data_source)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JoIlbnDlQFa2","colab_type":"text"},"source":["Define a function that we can use to plot same weather parameter across nodes."]},{"cell_type":"code","metadata":{"id":"buHFc1gbBe4K","colab_type":"code","colab":{}},"source":["def myPlot(df,param):\n","  find_vars = [col for col in df.columns if param in col]\n","  df[find_vars].plot(subplots=True,\n","                  figsize=(12, 8),title= param, grid=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vVRJI7aWQXCH","colab_type":"text"},"source":["Read RiverCore data"]},{"cell_type":"code","metadata":{"id":"dhtiyWXyrrW4","colab_type":"code","outputId":"0549739d-6212-4787-c963-931bdd5d080a","executionInfo":{"status":"ok","timestamp":1578952986648,"user_tz":0,"elapsed":927,"user":{"displayName":"Abdou KHOUAKHI","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCmeyp0CAemaGTjuHY2DFExPnmBmtIDxTLdxc8O6Q=s64","userId":"08254891030733884876"}},"colab":{"base_uri":"https://localhost:8080/","height":318}},"source":["rc_path = os.path.join(data_source,'rc_data.csv')\n","rc_data = pd.read_csv(rc_path,infer_datetime_format= True,\n","                  parse_dates=True,index_col='time_stamp')\n","rc_data.head()\n","rc_data.isna().sum()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["air_temp_Atmos1        473\n","relative_hum_Atmos1    473\n","solar_rad_Atmos1       473\n","vapor_press_Atmos1     473\n","prcp_Atmos1            473\n","air_temp_Atmos2        578\n","relative_hum_Atmos2    578\n","solar_rad_Atmos2       578\n","vapor_press_Atmos2     578\n","prcp_Atmos2            578\n","air_temp_Atmos3        728\n","relative_hum_Atmos3    728\n","solar_rad_Atmos3       728\n","vapor_press_Atmos3     728\n","prcp_Atmos3            728\n","wl_target                1\n","sm_target                1\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"0T55fhcNPu5Q","colab_type":"code","colab":{}},"source":["myPlot(rc_data,'prcp')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zr1Z2JOkQbZL","colab_type":"text"},"source":["Given large gaps in the data, we are going to keep only data for August "]},{"cell_type":"code","metadata":{"id":"hti0zULNyNEU","colab_type":"code","colab":{}},"source":["# keep data for August \n","rc_august = rc_data.loc['2019-08-01':'2019-09-10']\n","# check Nans\n","rc_august.isna().sum()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EG_scDahRASW","colab_type":"code","colab":{}},"source":["# plot \n","myPlot(rc_august,'relative_hum')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OdsgmD8aQrVh","colab_type":"text"},"source":["Fill the gaps with zeros for prcp and mean values for the rest of the paramaters"]},{"cell_type":"code","metadata":{"id":"8hvcq8xSKara","colab_type":"code","colab":{}},"source":["# fill prcp with zeros and the rest with mean \n","for column in rc_august:\n","  print(column)\n","  if 'prcp' in column:\n","    rc_august[column] = rc_august[column].fillna(0)\n","  else:\n","    rc_august[column] = rc_august[column].fillna(rc_august[column].mean())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"psrXc6Pkw9CL","colab_type":"text"},"source":["\n","\n","---\n","\n","Implement some basic machine learning models"]},{"cell_type":"code","metadata":{"id":"tA-sYGvjem-d","colab_type":"code","colab":{}},"source":["import sklearn.metrics as sm\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LinearRegression\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.svm import SVR\n","from sklearn.ensemble import RandomForestRegressor"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hv6u3-SkxBT8","colab_type":"text"},"source":["Re-arrange the data and put the the target station in the first column "]},{"cell_type":"code","metadata":{"id":"yPdXVCTH7gmt","colab_type":"code","colab":{}},"source":["# prepare the data\n","arranged = ['wl_target'] + list(rc_august.columns.drop('wl_target'))\n","rc_august = rc_august[arranged]\n","# to np array \n","rc_dataNp = rc_august.values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LcaL_cdlxgs1","colab_type":"text"},"source":["After the first preparation of the data, we now need to frame the dataset as a supervised learning problem.\n","For example we can re-arrange the data in a way that will allow predicting the water level at the target site at the current hour (t) given the water level measurements and other weather conditions at the prior time steps at the upstream site.\n","\n","The function below implement this by taking the data, the lead time desired and lag time (prior time steps desired to include in the inputs) "]},{"cell_type":"code","metadata":{"id":"_LAqNphP7yOQ","colab_type":"code","colab":{}},"source":["\t# convert time series into supervised learning problem\n","def to_lagLead(data, lead,lag, dropnan=True):\n","\tn_vars = data.shape[1]\n","\tdf = pd.DataFrame(data)\n","\tcols, names = list(), list()\n","\t# keep the tagret\n","\tcols.append(df.iloc[:,0])\n","\t# input sequence (t-n, ... t-1)\n","\tlag = lag + lead\n","\tfor i in range(lag, lead-1, -1): #i=2\n","\t\tcols.append(df.shift(i))\n","\t\tnames += [('input%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n","\t# put it all together\n","\tdf_all = pd.concat(cols, axis=1)\n","\tnames = [\"t\"] +names\n","\tdf_all.columns = names\n","\t# drop rows with NaN values\n","\tif dropnan:\n","\t  df_all.dropna(subset=[df_all.columns[1]],inplace=True) # drop only NAN's generagted by the lag process\n","\treturn df_all"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gSuNb5SC2Svy","colab_type":"text"},"source":["Below, we are going to prepare a dictionary of machine learning models, using the great [scikit-learn](https://scikit-learn.org/stable/) library.\n","For illustration, we are going to use a basic linear model, k nearest neighbor, Support Vector machine and a Random forest. "]},{"cell_type":"code","metadata":{"id":"Z_cowH6ms4zf","colab_type":"code","colab":{}},"source":["\t# prepare a list of ml models\n","def get_models(models=dict()):\n","  # linear models\n","  models['lr'] = LinearRegression()\n","  # non-linear models\n","  models['knn'] = KNeighborsRegressor()\n","  models['svmr'] = SVR()\n","  # ensemble models\n","  models['rf'] = RandomForestRegressor()\n","  print('The number of models are %d models:' % len(models))\n","  for key, value in models.items() :\n","    print (key)\n","  return models"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oZwaCEag3wxZ","colab_type":"text"},"source":["Data pre-processing is an essential step in machine learning, for example, Normalization which is a technique often applied as part of data preparation for machine learning. The goal is to change the values of numeric variables in the dataset to a common scale, without distorting differences in the ranges of values.\n","\n","For that, we will be using the scikit-learn, Pipelines to be able to chain multiple steps (e.g. different types of pre-processing techniques). \n","For more info refer to the scikit-learn, [Pipelines](https://scikit-learn.org/stable/modules/compose.html) "]},{"cell_type":"code","metadata":{"id":"8ZbSc6aVs8Qq","colab_type":"code","colab":{}},"source":["\t# create a feature preparation pipeline for a model\n","def make_pipeline(model,scaleType):\n","  steps = list()\n","  # standardization\n","  if scaleType = 'standardize':\n","    steps.append(('standardize', StandardScaler()))\n","  # normalization\n","  if scaleType = 'normalize':\n","      steps.append(('normalize', MinMaxScaler()))\n","  # the model\n","  steps.append(('model', model))\n","  # create pipeline\n","  pipeline = Pipeline(steps=steps)\n","  return pipeline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gqVB9kc89cWN","colab_type":"text"},"source":["Let's run an experiment where we will predict the water level 4 hours ahead using lagged inputs of up to 4 hours for each variable including data from the target site. This can be achieved using the defined above function `to_lagLead` "]},{"cell_type":"code","metadata":{"id":"NQaj58WkQ_-J","colab_type":"code","colab":{}},"source":["# run the experiement \n","lagged_data =to_lagLead(rc_dataNp, lead = 4, lag = 4) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w3xCqYQy_qrx","colab_type":"text"},"source":["Here we use the [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) `train_test_split` to split the data to train and test. "]},{"cell_type":"code","metadata":{"id":"lz5u8yrf_rMY","colab_type":"code","colab":{}},"source":["# train and test split \n","train, test = train_test_split(lagged_data.values, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KNwqnvikAmuq","colab_type":"text"},"source":["Define train and target for both train set and test set "]},{"cell_type":"code","metadata":{"id":"mFQ_W_poAbXn","colab_type":"code","colab":{}},"source":["# define train and target\n","train_X, train_y = train[:, 1:], train[:, 0]\n","test_X, test_y = test[:, 1:], test[:, 0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S5LjZcjpA56M","colab_type":"text"},"source":["get the defined models"]},{"cell_type":"code","metadata":{"id":"Ud82-naJRQIV","colab_type":"code","colab":{}},"source":["# make pipeline\n","models = get_models()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vUMZqvzSDOS-","colab_type":"text"},"source":["Below we fit each defined model to the train data and make a prediction using the test set then calculate performance the score for each model. "]},{"cell_type":"code","metadata":{"id":"3nP-DhzyOElt","colab_type":"code","colab":{}},"source":["scores = pd.DataFrame()\n","for name, model in models.items():\n","  print('model: %s' % name)\n","  pipeline = make_pipeline(model, True)\n","  # fit the model\n","  pipeline.fit(train_X, train_y)\n","  # forecast\n","  yhat = pipeline.predict(test_X)\n","  # calculate scores\n","  rmse = sqrt(sm.mean_squared_error(test_y, yhat))\n","  mae = sm.mean_absolute_error(test_y, yhat)\n","  r2 = sm.r2_score(test_y, yhat)\n","  ev = sm.explained_variance_score(test_y, yhat)\n","  df = {'model' : name,'rmse' : rmse,'mae' : mae,\n","        'r2' : r2,'ev':ev}\n","  scores = scores.append(df,ignore_index=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sY4W-1ZZEH8e","colab_type":"text"},"source":["Plot rmse and mae "]},{"cell_type":"code","metadata":{"id":"Qs_lMKz1RXaR","colab_type":"code","colab":{}},"source":["scores.plot(x = 'model',y = ['rmse','mae'], style='.-')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Jl_uLcMELuG","colab_type":"text"},"source":["plot R2 and EV "]},{"cell_type":"code","metadata":{"id":"MFPzVvY1RbRl","colab_type":"code","colab":{}},"source":["scores.plot(x = 'model',y = ['r2','ev'], style='.-')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ol9lNv0dESrT","colab_type":"text"},"source":["Plot predicted and observed data using the best model."]},{"cell_type":"code","metadata":{"id":"kI8pjjAIRdTJ","colab_type":"code","colab":{}},"source":["obs_pred.plot(subplots = False)"],"execution_count":0,"outputs":[]}]}